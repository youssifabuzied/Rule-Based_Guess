{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-10 23:04:36,535 - src.domain.models.QwenModel - INFO - Initializing QwenModel with ahmedheakl/ex19_qwen2.5-1.5b-1m-stack-16kcw on device mps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Qwen model: ahmedheakl/ex19_qwen2.5-1.5b-1m-stack-16kcw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-10 23:04:43,112 - QwenModel - INFO - Initialized QwenModel on device: mps:0\n",
      "2025-05-10 23:04:43,113 - src.domain.models.QwenModel - INFO - Model initialization completed in 6.58 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source JSONL: data/processed/X86/BringUp_x86.jsonl\n",
      "Target JSONL: data/processed/ARM64/BringUp_arm.jsonl\n",
      "Loading file: data/processed/X86/BringUp_x86.jsonl\n",
      "Loaded 31 entries from data/processed/X86/BringUp_x86.jsonl\n",
      "Loading file: data/processed/ARM64/BringUp_arm.jsonl\n",
      "Loaded 31 entries from data/processed/ARM64/BringUp_arm.jsonl\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'generator' object has no attribute 'next'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[57]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m config = Config(ConfigType.QWEN_X862ARM64.get_path())\n\u001b[32m      9\u001b[39m guess = Guess(config=config)\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m test_instance = \u001b[43mguess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m.\u001b[49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnext\u001b[49m()\n\u001b[32m     13\u001b[39m result = guess.model.predict(test_instance, guess.inference_cfg)\n",
      "\u001b[31mAttributeError\u001b[39m: 'generator' object has no attribute 'next'"
     ]
    }
   ],
   "source": [
    "from src.guess.guess import ConfigType, Guess, Config\n",
    "from src.domain.datasets.UnixCommandDataset import UnixCommandDataset  # Register dataset\n",
    "from src.domain.datasets.ProjectEulerDataset import ProjectEulerDataset\n",
    "from src.domain.datasets.BringUpDataset import BringUpDataset\n",
    "\n",
    "prediction = None\n",
    "\n",
    "config = Config(ConfigType.QWEN_X862ARM64.get_path())\n",
    "guess = Guess(config=config)\n",
    "\n",
    "test_instance = guess.data_loader.iter().__next__()\n",
    "\n",
    "result = guess.model.predict(test_instance, guess.inference_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['fy-shuffle.s', 'bloom-filter.s', 'strange.s', 'topo-sort.s', 'weekday.s', 'knights-tour.s', 'murmur-hash.s', 'spirograph.s', 'gcd-list.s', 'skeleton.s', 'simple-grep.s', 'pi-calc.s', 'indirect-test.s', 'flood-fill.s', 'priority-queue.s', 'bubble-sort.s', 'ackermann.s', 'spelt2num.s', 'totient.s', 'cipher.s', 'mersenne.s', 'heapsort.s', 'sieve.s', 'hanoi.s', 'natlog.s', 'rle-compress.s', 'quine.s', 'mandelbrot.s'])\n"
     ]
    }
   ],
   "source": [
    "from src.helpers.torch_unpicker import CPU_Unpickler\n",
    "\n",
    "predictions = CPU_Unpickler(open(\"bringup_wAttention_Tokenized.pkl\", \"rb\")).load()\n",
    "print(predictions.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.sketch.sketch import Sketch\n",
    "\n",
    "sketch = Sketch(config, guess.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from src.sketch.sections import Section\n",
    "from src.sketch.sketch import Sketch\n",
    "from src.helpers.model import PredictionResult\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "def section_confidence(section: Section, prediction: PredictionResult) -> float:\n",
    "    return prediction.confidence[section.start:section.end].mean()\n",
    "\n",
    "\n",
    "def remove_sections(sections: List[Section], prediction: PredictionResult) -> PredictionResult:\n",
    "    pred = prediction.pred[0]\n",
    "    confidence = prediction.confidence\n",
    "    alignments = prediction.alignments\n",
    "\n",
    "    print(len(pred))\n",
    "    print(len(confidence))\n",
    "    print(len(alignments))\n",
    "\n",
    "    sections.sort(key=lambda section: section.start)\n",
    "    \n",
    "    mask = np.ones(len(pred), dtype=bool)\n",
    "    \n",
    "    for section in sections:\n",
    "        mask[section.start:section.end] = False\n",
    "    \n",
    "    filtered_pred = pred[mask]\n",
    "    filtered_confidence = confidence[mask]\n",
    "    filtered_alignments = alignments[mask] if alignments is not None else None\n",
    "    \n",
    "    return PredictionResult(\n",
    "        instance_id=prediction.instance_id,\n",
    "        source=prediction.source,\n",
    "        pred=[filtered_pred],\n",
    "        alignments=filtered_alignments,\n",
    "        confidence=filtered_confidence\n",
    "    )\n",
    "\n",
    "\n",
    "def fix_duplicate_sections(sketch: Sketch, prediction: PredictionResult) -> PredictionResult:\n",
    "    cleaned_pred = prediction\n",
    "\n",
    "    sections = sketch.extract_sections(prediction.pred)\n",
    "    sections_by_name = {}\n",
    "    for section in sections:\n",
    "        if section.name in sections_by_name:\n",
    "            sections_by_name[section.name].append(section)\n",
    "        else:\n",
    "            sections_by_name[section.name] = [section]\n",
    "    \n",
    "    for section_name, sections in sections_by_name.items():\n",
    "        if len(sections) > 1:\n",
    "            sections.sort(key=lambda section: section_confidence(section, prediction), reverse=True)\n",
    "\n",
    "            cleaned_pred = remove_sections(sections[1:], cleaned_pred)\n",
    "\n",
    "    return cleaned_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fy-shuffle.s\n",
      "3705\n",
      "100\n",
      "7410\n",
      "bloom-filter.s\n",
      "4019\n",
      "100\n",
      "8038\n",
      "strange.s\n",
      "978\n",
      "100\n",
      "1956\n",
      "topo-sort.s\n",
      "4743\n",
      "100\n",
      "9486\n",
      "weekday.s\n",
      "3082\n",
      "100\n",
      "6164\n",
      "knights-tour.s\n",
      "4814\n",
      "100\n",
      "9628\n",
      "4814\n",
      "9628\n",
      "100\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "The shape of the mask [4814] at index 0 does not match the shape of the indexed tensor [9628] at index 0",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[56]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(prediction.confidence))\n\u001b[32m     10\u001b[39m pred = PredictionResult(\n\u001b[32m     11\u001b[39m     instance_id=instance_id,\n\u001b[32m     12\u001b[39m     source=[torch.tensor(prediction.source, dtype=torch.long)],\n\u001b[32m   (...)\u001b[39m\u001b[32m     15\u001b[39m     confidence=torch.tensor(prediction.confidence, dtype=torch.float32)\n\u001b[32m     16\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m fixed_pred = \u001b[43mfix_duplicate_sections\u001b[49m\u001b[43m(\u001b[49m\u001b[43msketch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[54]\u001b[39m\u001b[32m, line 57\u001b[39m, in \u001b[36mfix_duplicate_sections\u001b[39m\u001b[34m(sketch, prediction)\u001b[39m\n\u001b[32m     54\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(sections) > \u001b[32m1\u001b[39m:\n\u001b[32m     55\u001b[39m         sections.sort(key=\u001b[38;5;28;01mlambda\u001b[39;00m section: section_confidence(section, prediction), reverse=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m         cleaned_pred = \u001b[43mremove_sections\u001b[49m\u001b[43m(\u001b[49m\u001b[43msections\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcleaned_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cleaned_pred\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[54]\u001b[39m\u001b[32m, line 30\u001b[39m, in \u001b[36mremove_sections\u001b[39m\u001b[34m(sections, prediction)\u001b[39m\n\u001b[32m     27\u001b[39m     mask[section.start:section.end] = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     29\u001b[39m filtered_pred = pred[mask]\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m filtered_confidence = \u001b[43mconfidence\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     31\u001b[39m filtered_alignments = alignments[mask] \u001b[38;5;28;01mif\u001b[39;00m alignments \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m PredictionResult(\n\u001b[32m     34\u001b[39m     instance_id=prediction.instance_id,\n\u001b[32m     35\u001b[39m     source=prediction.source,\n\u001b[32m   (...)\u001b[39m\u001b[32m     38\u001b[39m     confidence=filtered_confidence\n\u001b[32m     39\u001b[39m )\n",
      "\u001b[31mIndexError\u001b[39m: The shape of the mask [4814] at index 0 does not match the shape of the indexed tensor [9628] at index 0"
     ]
    }
   ],
   "source": [
    "from src.helpers.model import PredictionResult\n",
    "\n",
    "for instance_id, prediction in predictions.items():\n",
    "    print(instance_id)\n",
    "\n",
    "    print(len(prediction.pred))\n",
    "    print(len(prediction.alignments))\n",
    "    print(len(prediction.confidence))\n",
    "\n",
    "    pred = PredictionResult(\n",
    "        instance_id=instance_id,\n",
    "        source=[torch.tensor(prediction.source, dtype=torch.long)],\n",
    "        pred=[torch.tensor(prediction.pred, dtype=torch.long)],\n",
    "        alignments=torch.tensor(prediction.alignments, dtype=torch.long),\n",
    "        confidence=torch.tensor(prediction.confidence, dtype=torch.float32)\n",
    "    )\n",
    "    \n",
    "    fixed_pred = fix_duplicate_sections(sketch, pred)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
